# -*- coding: utf-8 -*-
"""CapstoneProjectAishwaryaD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ftDTz6LmhfuKDKmOze0IYPLVNRKRN_V2
"""

!pip install pathway

import pathway as pw

!pip install pathway bokeh --quiet

"""Import the required Dependencies

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime
from datetime import datetime
import bokeh.plotting
import panel as pn

df=pd.read_csv("/content/dataset.csv")
df

df['Timestamp']=pd.to_datetime(df['LastUpdatedDate']+' '+df['LastUpdatedTime'],format="%d-%m-%Y %H:%M:%S")  #merged 2 columns into single 'Timestamp'

df=df.sort_values('Timestamp').reset_index(drop=True)

df[["Timestamp", "Occupancy", "Capacity","VehicleType","IsSpecialDay"]].to_csv("parking_stream.csv", index=False)

class ParkingSchema(pw.Schema):
    Timestamp: str   # Timestamp of the observation
    Occupancy: int   # Number of occupied parking spots
    Capacity: int    # Total parking capacity at the location

data = pw.demo.replay_csv("parking_stream.csv", schema=ParkingSchema, input_rate=1000)

fmt = "%Y-%m-%d %H:%M:%S"

"""data_with_time = data.with_columns(
    t = data.Timestamp.dt.strptime(fmt),
    day = data.Timestamp.dt.strptime(fmt).dt.strftime("%Y-%m-%dT00:00:00")
)
 price=10 + (pw.this.occ_max - pw.this.occ_min) / pw.this.cap
    )
)
"""

import datetime

data_with_time = data.with_columns(
    t=pw.this.Timestamp.dt.strptime(fmt),  # Event time column parsed as datetime
    day=pw.this.Timestamp.dt.strptime(fmt).dt.strftime("%Y-%m-%dT00:00:00") # Day for partitioning
)

delta_window = (
    data_with_time.windowby(
        pw.this.t,  # Event time column to use for windowing (parsed datetime)
        instance=pw.this.day,  # Logical partitioning key: one instance per calendar day
        window=pw.temporal.tumbling(datetime.timedelta(days=1)),  # Fixed-size daily window
        behavior=pw.temporal.exactly_once_behavior()  # Guarantees exactly-once processing semantics
    )
    .reduce(
        t=pw.this._pw_window_end,                        # Assign the end timestamp of each window
        occ_max=pw.reducers.max(pw.this.Occupancy),      # Highest occupancy observed in the window
        occ_min=pw.reducers.min(pw.this.Occupancy),      # Lowest occupancy observed in the window
        cap=pw.reducers.max(pw.this.Capacity),           # Maximum capacity observed (typically constant per spot)
    )
    .with_columns(
         price=10 + (pw.this.occ_max - pw.this.occ_min) / pw.this.cap
    )
)

pn.extension()

# Define a custom Bokeh plotting function that takes a data source (from Pathway) and returns a figure
def price_plotter(source):
    # Create a Bokeh figure with datetime x-axis
    fig = bokeh.plotting.figure(
        height=400,
        width=800,
        title="Pathway: Daily Parking Price",
        x_axis_type="datetime",  # Ensure time-based data is properly formatted on the x-axis
    )
    # Plot a line graph showing how the price evolves over time
    fig.line("t", "price", source=source, line_width=2, color="navy")

    # Overlay red circles at each data point for better visibility
    fig.scatter("t", "price", source=source, size=6, color="red")

    return fig

# Use Pathway's built-in .plot() method to bind the data stream (delta_window) to the Bokeh plot
# - 'price_plotter' is the rendering function
# - 'sorting_col="t"' ensures the data is plotted in time order
viz = delta_window.plot(price_plotter, sorting_col="t")

# Create a Panel layout and make it servable as a web app
# This line enables the interactive plot to be displayed when the app is served
pn.Column(viz).servable()

# Commented out IPython magic to ensure Python compatibility.
# 
# %%capture --no-display
# pw.run()



"""Model 1: Baseline Linear Model"""

#MODEL 1
base_price=10
max_price=2*base_price
min_price=0.5*base_price



"""This section processes the data stream to calculate daily price based on occupancy and capacity."""

df.head(2)

def model1(df,alpha=2):
  df=df.copy()
  df['OccupancyRate']=df['Occupancy']/df['Capacity']
  df['Price_Model1']=base_price+alpha*df['OccupancyRate']
  df['Price_Model1']=df['Price_Model1'].clip(lower=min_price, upper=min_price)
  print(df.head())
  return df



# MODEL 2: DEMAND BASED PRICING # strategy: assign weights to parameters
weights={
    'Capacity':1.0,
    'Occupancy':1.0,
    'VehicleType': {
        'car':1,
        'bike':0.6,
        'truck':1.4,
        'cycle':0.4,
    },
    'TrafficConditionNearby':-0.4,
    'QueueLength':0.5,
    'IsSpecialDay':0.35,
}



def model2(df, alpha=0.5):
  df=df.copy()

  df['OccupancyRate']=df['Occupancy']/df['Capacity']
  df['VehicleWeight']=df['VehicleType'].map(weights['VehicleType'])

  # Map the 'TrafficConditionNearby' to numerical values
  traffic_mapping = {'low': 0.2, 'average': 0.6, 'high': 1.0} # Example mapping, adjust as needed
  df['TrafficWeight'] = df['TrafficConditionNearby'].map(traffic_mapping)


  df['DemandRaw']=(
     weights['Occupancy']*df['OccupancyRate']+weights['QueueLength']*df['QueueLength']+weights['TrafficConditionNearby']*df['TrafficWeight']+0.3*df['IsSpecialDay']+df['VehicleWeight']
  )

  df['DemandNorm']=(df['DemandRaw']-df['DemandRaw'].min())/(df['DemandRaw'].max()-df['DemandRaw'].min()+1e-6)
  df['Price_Model2'] = base_price + alpha * df['DemandNorm']
  df['Price_Model2']=df['Price_Model2'].clip(lower=min_price, upper=max_price)

  return df

# New df contains occupancyrate,vehicle weight, demand raw,and gives the predicted price as per model2
new_df = model2(df)
new_df.head()



from geopy.distance import geodesic # this is a python librarby to calculate distance between latitude and longitude

def compute_distance_matrix(df):
  lots=df[['ID','Latitude','Longitude']].drop_duplicates()
  distances={} #empty list
  #check for all parking lots
  for i,row1 in lots.iterrows():
    for j,row2 in lots.iterrows():
      if row1['ID'] !=row2['ID']:
        d=geodesic((row1['Latitude'], row1['Longitude']),
                   (row2['Latitude'],row2['Longitude'])).meters
        distances[(row1['ID'],row2['ID'])]=d  # distances stored as tuple
    return distances

distance_matrix=compute_distance_matrix(df)

print(distance_matrix)



"""Model 3: Competitive Pricing Model


"""

def model_3(df, distance_matrix, radius=500):
    df = df.copy()
    df['Price_Model3'] = df['Price_Model2']  # Start from Model 2

    for idx, row in df.iterrows():
        lot_id = row['ID']
        competitors = [k[1] for k in distance_matrix if k[0] == lot_id and distance_matrix[k] <= radius] # a parking lot is competitor if it is nearer or empty(we assumed a value for radius i.e 500)

        nearby_prices = df[(df['ID'].isin(competitors)) & (df['Timestamp'] == row['Timestamp'])]['Price_Model2'] # comparing prices in real time to dynamicaly adjust


        if not nearby_prices.empty:
            avg_competitor_price = nearby_prices.mean()
            if row['Occupancy'] >= row['Capacity']:  # Parking already full exceeding its capacity, lower the price
                if avg_competitor_price < row['Price_Model3']:
                    df.at[idx, 'Price_Model3'] = max(avg_competitor_price, min_price)  # Match competitor
            else:  # increase the price
                if avg_competitor_price > row['Price_Model3']:
                    df.at[idx, 'Price_Model3'] = min(avg_competitor_price + 1, max_price)
    return df

output_df=model_3(new_df,distance_matrix)
print(output_df[['ID','Timestamp','Price_Model2','Price_Model3']].head()) # This df outputs the price as per model 2 and model 3 both

from bokeh.models import ColumnDataSource
from bokeh.plotting import figure, show, output_notebook
from bokeh.layouts import column
from bokeh.palettes import Category10
output_notebook()

# Example: Filter one lot for time-series pricing
lot_id = 'P1'
df_plot = df_model3[df_model3['ID'] == lot_id].sort_values('Timestamp')

# Create a ColumnDataSource
source = ColumnDataSource(data={
    'Timestamp': df_plot['Timestamp'],
    'Model2': df_plot['Price_Model2'],
    'Model3': df_plot['Price_Model3'],
})